import streamlit as st
import pandas as pd
import numpy as np
import joblib
import os
import torch
import torch.nn as nn
import plotly.express as px
import plotly.graph_objects as go
import google.generativeai as genai

# ---------------------------------------------------------
# [ì„¤ì •] í˜ì´ì§€ ìŠ¤íƒ€ì¼
# ---------------------------------------------------------
st.set_page_config(page_title="AI Co-Scientist: Deep Optimization", page_icon="ğŸ§¬", layout="wide")
st.markdown("""
<style>
    .stApp { background-color: #0E1117; color: #FAFAFA; }
    .gemini-box { background-color: #1E1E1E; padding: 20px; border-left: 5px solid #8e44ad; border-radius: 10px; margin-top:10px;}
    .metric-box { background-color: #262730; padding: 15px; border-radius: 8px; text-align: center; border: 1px solid #444; }
</style>
""", unsafe_allow_html=True)

# ---------------------------------------------------------
# [0] ë¦¬ì†ŒìŠ¤ ë¡œë”©
# ---------------------------------------------------------
class ExpertAI(nn.Module):
    def __init__(self):
        super(ExpertAI, self).__init__()
        self.net = nn.Sequential(
            nn.Linear(5, 128), nn.ReLU(), nn.Dropout(0.1),
            nn.Linear(128, 256), nn.ReLU(), nn.Dropout(0.1),
            nn.Linear(256, 128), nn.ReLU(), nn.Dropout(0.1),
            nn.Linear(128, 2) 
        )
    def forward(self, x): return self.net(x)

@st.cache_resource
def load_system():
    # ë°°í¬ í™˜ê²½ê³¼ ë¡œì»¬ í™˜ê²½ ê²½ë¡œ í˜¸í™˜ì„± í™•ë³´
    base = os.getcwd()
    model_path = os.path.join(base, '04_Trained_Model', 'real_model.pth')
    db_path = os.path.join(base, '03_Model_Input', 'real_paper_db.csv')
    
    # íŒŒì¼ì´ ì—†ìœ¼ë©´ None ë°˜í™˜
    if not os.path.exists(model_path) or not os.path.exists(db_path): 
        return None, None, None, None
    
    model = ExpertAI()
    model.load_state_dict(torch.load(model_path, map_location='cpu'))
    model.train() # MC Dropout í™œì„±í™”
    
    sx = joblib.load(os.path.join(base, '04_Trained_Model', 'scaler_X_real.pkl'))
    sy = joblib.load(os.path.join(base, '04_Trained_Model', 'scaler_y_real.pkl'))
    df = pd.read_csv(db_path)
    return model, sx, sy, df

model, sx, sy, df_db = load_system()

# ---------------------------------------------------------
# [1] í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜ë“¤
# ---------------------------------------------------------
def predict_with_uncertainty(X_tensor, n_iter=20):
    preds = []
    with torch.no_grad():
        for _ in range(n_iter):
            preds.append(model(X_tensor).numpy())
    preds = np.array(preds)
    
    mean_pred = preds.mean(axis=0)
    std_pred = preds.std(axis=0)
    
    final_mean = sy.inverse_transform(mean_pred)
    scale_factor = sy.data_max_ - sy.data_min_
    final_std = std_pred * scale_factor
    
    return final_mean, final_std

def run_genetic_algorithm(min_temp, max_temp, thickness):
    pop_size = 300
    pop = []
    for _ in range(pop_size):
        r = np.random.rand(4); r /= r.sum()
        t = np.random.randint(min_temp, max_temp)
        pop.append(list(r) + [t])
    
    df_pop = pd.DataFrame(pop, columns=['In','Ga','Zn','Sn','Temp'])
    
    thick_factor_mob = np.log10(thickness + 10) / np.log10(60) 
    thick_factor_stab = 1.0 
    
    for _ in range(10): 
        X = sx.transform(df_pop.values)
        model.eval() 
        with torch.no_grad():
            pred = sy.inverse_transform(model(torch.tensor(X, dtype=torch.float32)).detach().numpy())
        model.train() 
        
        df_pop['Mobility'] = pred[:,0] * thick_factor_mob
        df_pop['Stability'] = pred[:,1] * thick_factor_stab
        df_pop['Score'] = df_pop['Mobility'] - (df_pop['Stability'] * 5)
        
        top = df_pop.sort_values('Score', ascending=False).head(int(pop_size*0.2))
        new_pop = top.values[:,:5].tolist()
        
        while len(new_pop) < pop_size:
            p = top.sample(2).values[:,:5]
            child = (p[0] + p[1]) / 2
            if np.random.rand() < 0.1: 
                child[:4] += np.random.normal(0,0.05,4); child[:4] = np.clip(child[:4],0,1); child[:4] /= child[:4].sum()
                child[4] = np.clip(child[4] + np.random.randint(-20,20), min_temp, max_temp)
            new_pop.append(child)
        df_pop = pd.DataFrame(new_pop, columns=['In','Ga','Zn','Sn','Temp'])
    
    # ì ìˆ˜ ì¬ê³„ì‚°
    X_final = sx.transform(df_pop.values)
    model.eval()
    with torch.no_grad():
        pred_final = sy.inverse_transform(model(torch.tensor(X_final, dtype=torch.float32)).detach().numpy())
    model.train()
    
    df_pop['Mobility'] = pred_final[:,0] * thick_factor_mob
    df_pop['Stability'] = pred_final[:,1] * thick_factor_stab
    df_pop['Score'] = df_pop['Mobility'] - (df_pop['Stability'] * 5)
    
    final_res = df_pop.sort_values('Score', ascending=False)
    min_s, max_s = final_res['Score'].min(), final_res['Score'].max()
    final_res['PlotSize'] = 5 + ((final_res['Score'] - min_s) / (max_s - min_s + 1e-9)) * 15
    return final_res

def plot_radar(row):
    mob_s = min(100, (row['Mobility']/80)*100)
    stab_s = min(100, max(0, (1.0-row['Stability'])*100))
    proc_s = 100 if row['Temp'] < 350 else 60
    
    fig = go.Figure(go.Scatterpolar(
        r=[mob_s, stab_s, proc_s, mob_s*0.9, 80, mob_s],
        theta=['Mobility', 'Stability', 'Process', 'Low Power', 'Cost', 'Mobility'],
        fill='toself', name='Candidate'
    ))
    fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0, 100])), showlegend=False, height=300, margin=dict(l=30, r=30, t=20, b=20))
    return fig

def find_evidence(in_r, ga_r, zn_r, sn_r, temp):
    if df_db.empty: return None
    d = np.sqrt((df_db['In']-in_r)**2 + (df_db['Ga']-ga_r)**2 + (df_db['Sn']-sn_r)**2 + ((df_db['Temp']-temp)/500)**2)
    return df_db.loc[d.nsmallest(1).index].iloc[0]

def ask_gemini(api_key, evidence, u):
    try:
        genai.configure(api_key=api_key)
        # 2.5 Flash ëª¨ë¸ ì‚¬ìš©
        g_model = genai.GenerativeModel("models/gemini-2.5-flash")
        prompt = f"""
        ë‹¹ì‹ ì€ ë°˜ë„ì²´ ë¶„ì•¼ì—ì„œ ìµœê³ ë¡œ ê¶Œìœ„ê°€ ìˆëŠ” ì—°êµ¬ì›ì…ë‹ˆë‹¤.
        [ê·¼ê±° ë…¼ë¬¸]: {evidence['Paper_ID']} (Mechanism: {evidence['Mechanism']})
        [ì œì•ˆ ì¡°ê±´]: In:{u['In']:.2f}, Ga:{u['Ga']:.2f}, Sn:{u['Sn']:.2f}, Temp:{u['Temp']}C, Thickness:{u['Thick']}nm
        
        1. ì´ ì œì•ˆì´ ê³ ì„±ëŠ¥(ì´ë™ë„)ê³¼ ê³ ì‹ ë¢°ì„±(ì•ˆì •ì„±)ì„ ëª¨ë‘ ë§Œì¡±í•˜ëŠ” ì´ìœ ë¥¼ ë…¼ë¦¬ì ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
        2. íŠ¹íˆ ì‚¬ìš©ìê°€ ì„¤ì •í•œ ë‘ê»˜({u['Thick']}nm)ì™€ ì˜¨ë„({u['Temp']}C)ê°€ Flexible AMOLED ê³µì •ì— ì í•©í•œì§€ êµ¬ì²´ì ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”.
        """
        return g_model.generate_content(prompt).text
    except Exception as e: return f"Error: {e}"

# ---------------------------------------------------------
# [2] UI êµ¬ì„± (Secrets ì—°ë™ ë¶€ë¶„ ìˆ˜ì •ë¨)
# ---------------------------------------------------------
st.title("ğŸ§¬ AI Co-Scientist: Deep Optimization")
st.markdown("#### Evidence-Based Candidate Discovery (Powered by Genetic Algorithm)")

with st.sidebar:
    st.header("âš™ï¸ Settings")
    
    # [í•µì‹¬ ìˆ˜ì •] Secretsì—ì„œ ë¨¼ì € í‚¤ë¥¼ ì°¾ê³ , ì—†ìœ¼ë©´ ì…ë ¥ì°½ í‘œì‹œ
    if "GEMINI_API_KEY" in st.secrets:
        api_key = st.secrets["GEMINI_API_KEY"]
        st.success("âœ… API Key Loaded from Server")
    else:
        api_key = st.text_input("Gemini API Key", type="password")
        st.caption("ë°°í¬ í™˜ê²½ì—ì„œëŠ” Secretsê°€ ìë™ ë¡œë“œë©ë‹ˆë‹¤.")
    
    st.markdown("---")
    st.markdown("**1. Process Constraints**")
    min_temp, max_temp = st.slider("Temp Range (Â°C)", 100, 500, (200, 350))
    thickness = st.slider("Active Layer Thickness (nm)", 10, 100, 50)
    
    st.markdown("**2. Target Performance**")
    target_mob = st.number_input("Target Mobility (>)", 30.0)

if model is None:
    st.error("ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨. GitHubì— '03_Model_Input'ê³¼ '04_Trained_Model' í´ë”ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

tab1, tab2 = st.tabs(["ğŸš€ Evolutionary Search", "ğŸ”¬ Researcher's Lab"])

# === Tab 1: ìœ ì „ ì•Œê³ ë¦¬ì¦˜ ===
with tab1:
    if st.button("ğŸš€ Run Genetic Algorithm", type="primary"):
        with st.spinner("Evolving candidates with Physics-aware logic..."):
            res = run_genetic_algorithm(min_temp, max_temp, thickness)
            top3 = res[res['Mobility'] > target_mob].head(3)
            
            if top3.empty: st.warning("ì¡°ê±´ ë§Œì¡± í›„ë³´ ì—†ìŒ.")
            else:
                st.success(f"âœ… Optimization Complete! (Physics Adjusted for {thickness}nm)")
                c1, c2 = st.columns([1.2, 1])
                with c1:
                    for i in range(len(top3)):
                        row = top3.iloc[i]
                        with st.expander(f"ğŸ¥‡ Rank {i+1}: In-rich IGZTO (Mob: {row['Mobility']:.1f})", expanded=(i==0)):
                            st.plotly_chart(plot_radar(row), use_container_width=True)
                            st.caption(f"In {row['In']:.2f} : Sn {row['Sn']:.2f} @ {row['Temp']:.0f}Â°C, {thickness}nm")
                with c2:
                    st.subheader("ğŸŒŒ Search Space")
                    fig = px.scatter_ternary(res.head(300), a="In", b="Ga", c="Sn", color="Mobility", size="PlotSize", color_continuous_scale="Viridis")
                    st.plotly_chart(fig, use_container_width=True)

# === Tab 2: ì—°êµ¬ì ëª¨ë“œ ===
with tab2:
    c1, c2 = st.columns([1,1])
    with c1:
        in_r = st.slider("In",0.0,1.0,0.4); sn_r = st.slider("Sn",0.0,1.0,0.1)
        temp = st.slider("Temp",100,500,300)
    with c2:
        rem = max(0, 1.0-in_r-sn_r); ga_r = rem*0.3; zn_r = rem*0.7
        st.info(f"Auto-Calc: Ga {ga_r:.2f} / Zn {zn_r:.2f}")
        
        # ë¶ˆí™•ì‹¤ì„± ì˜ˆì¸¡
        X = sx.transform([[in_r, ga_r, zn_r, sn_r, temp]])
        mu, sigma = predict_with_uncertainty(torch.tensor(X, dtype=torch.float32))
        
        # ë‘ê»˜ ë³´ì •
        thick_factor = np.log10(thickness + 10) / np.log10(60)
        final_mob = mu[0,0] * thick_factor
        final_stab = mu[0,1]
        
        st.metric("Predicted Mobility", f"{final_mob:.1f} Â± {sigma[0,0]:.1f}")
        st.metric("Predicted Stability", f"{final_stab:.2f} Â± {sigma[0,1]:.2f}")
        
        ev = find_evidence(in_r, ga_r, zn_r, sn_r, temp)
        if api_key and st.button("ğŸ§  Deep Analysis"):
            with st.spinner("Analyzing..."):
                u = {'In':in_r, 'Ga':ga_r, 'Zn':zn_r, 'Sn':sn_r, 'Temp':temp, 'Thick':thickness}
                st.markdown(f"<div class='gemini-box'>{ask_gemini(api_key, ev, u)}</div>", unsafe_allow_html=True)
